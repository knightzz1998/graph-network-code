{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 基于 MessagePassing 构建图神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义图神经网络模型\n",
    "\n",
    "GCNConv 的数学定义为 :\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{i}^{(k)}=\\sum_{j \\in \\mathcal{N}(i) \\cup\\{i\\}} \\frac{1}{\\sqrt{\\operatorname{deg}(i)} \\cdot \\sqrt{\\operatorname{deg}(j)}} \\cdot\\left(\\boldsymbol{\\Theta} \\cdot \\mathbf{x}_{j}^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "其中，邻接节点的表征$x_{j}^{(k-1)}$首先通过与权重矩阵 相乘进行变换，然后按端点的度 $deg(i), deg(j)$\n",
    "进行归一化处理，最后进行求和。这个公式可以分为以下几个步骤 :\n",
    "\n",
    "1. 向邻接矩阵添加自环边。\n",
    "2. 对节点表征做线性转换。\n",
    "3. 计算归一化系数。\n",
    "4. 归一化邻接节点的节点表征。\n",
    "5. 将相邻节点表征相加（\"求和 \"聚合）\n",
    "\n",
    "步骤1-3通常是在消息传递发生之前计算的。\n",
    "步骤4-5可以使用MessagePassing基类轻松处理。该层的全部实现如下所示。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n",
    "        # aggr : 聚合方式 => add\n",
    "        # flow=\"source_to_target\" : 表示消息从源节点传播到目标节点\n",
    "        self.linear = torch.nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        :param x: [num_nodes, in_channels]\n",
    "        :param edge_index: [2, num_edges]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # step 1 : 向邻接矩阵添加自环边\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # step 2 : 对节点表征做线性变换\n",
    "        x = self.linear(x)\n",
    "        # step 3 : 计算归一化系数\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # step 4-5 : 开启消息传播\n",
    "        return self.propagate(edge_index=edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        \"\"\"\n",
    "        :param x_j: [num_edges, out_channels]\n",
    "        :param norm: 归一化系数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return norm.view(-1, 1) * x_j"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型详解 :\n",
    "\n",
    "1. GCNConv继承了MessagePassing并以\"求和\"作为领域节点信息聚合方式。\n",
    "2. 该层的所有 逻 辑 都 发 生 在 其 forward() 方法中\n",
    "3. 在这 里, 我 们 首 先 使 用 torch_geometric.utils.add_self_loops()函数向我们的边索引添加自循环边（步骤1）\n",
    "4. 以及通过调用torch.nn.Linear实例对节点表征进行线性变换（步骤2）。\n",
    "5. propagate()方法也在forward方法中被调用，propagate()方法被调用后节点间的信息传递开始执行\n",
    "6. 归一化系数是由每个节点的节点度得出的，它被转换为每条边的节点度。结果被保存在形状为[num_edges,]的变量norm中（步骤3）\n",
    "7. 在message()方法中，我们需要通过norm对邻接节点表征x_j进行归一化处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过以上内容的学习，我们便掌握了创建一个仅包含一次“消息传递过程”的图神经\n",
    "网络的方法。如下方代码所示，我们可以很方便地初始化和调用它："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "datasets = Planetoid(root='../../datasets/Cora', name=\"Cora\")\n",
    "# 获取第一张图\n",
    "data = datasets[0]\n",
    "print(\"num_features : {}, \")\n",
    "# 创建模型 : GCNConv(节点特征, out_channel)\n",
    "net = GCNConv(data.num_features, 64)\n",
    "# x : 节点属性矩阵，大小为 [num_nodes, num_node_features]\n",
    "# edge_index : 边索引矩阵，大小为[2, num_edges]\n",
    "# 第 0 行可称为头（head）节点、源（source）节点、邻接节点，第 1 行可称为尾（tail）节点、目标（target）节点、中心节点\n",
    "h_nodes = net(data.x, data.edge_index)\n",
    "print(h_nodes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过串联多个这样的简单图神经网络，我们就可以构造复杂的图神经网络模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 重写message方法\n",
    "\n",
    "前面我们介绍了，传递给propagate()方法的参数，如果是节点的属性的话，可以 被拆分成属于中心节点的部分和属于邻接节点的部分, 只需在变量名后面加上_i或 _j。\n",
    "现在我们有一个额外的节点属性，节点的度deg, 我们希望message方法还能接 收中心节点的度，我们对前面GCNConv的message方法进行改造得到新的GCNConv类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n",
    "        # aggr : 聚合方式 => add\n",
    "        # flow=\"source_to_target\" : 表示消息从源节点传播到目标节点\n",
    "        self.linear = torch.nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        :param x: [num_nodes, in_channels]\n",
    "        :param edge_index: [2, num_edges]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # step 1 : 向邻接矩阵添加自环边\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # step 2 : 对节点表征做线性变换\n",
    "        x = self.linear(x)\n",
    "        # step 3 : 计算归一化系数\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # step 4-5 : 开启消息传播\n",
    "        return self.propagate(edge_index=edge_index, x=x, norm=norm, deg=deg.view(-1, 1))\n",
    "\n",
    "    def message(self, x_j, norm, deg_i):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_j: [num_edges, out_channels]\n",
    "        :param norm: 归一化系数\n",
    "        :param deg_i:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return norm.view(-1, 1) * x_j * deg_i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features : 1433, \n",
      "torch.Size([2708, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "datasets = Planetoid(root='../../datasets/Cora', name=\"Cora\")\n",
    "# 获取第一张图\n",
    "data = datasets[0]\n",
    "print(\"num_features : {}, \".format(data.num_features))\n",
    "# 创建模型 : GCNConv(节点特征, out_channel)\n",
    "net = GCNConv(data.num_features, 64)\n",
    "# x : 节点属性矩阵，大小为 [num_nodes, num_node_features]\n",
    "# edge_index : 边索引矩阵，大小为[2, num_edges]\n",
    "# 第 0 行可称为头（head）节点、源（source）节点、邻接节点，第 1 行可称为尾（tail）节点、目标（target）节点、中心节点\n",
    "h_nodes = net(data.x, data.edge_index)\n",
    "print(h_nodes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "若一个数据可以被拆分成属于中心节点的部分和属于邻接节点的部分，其形状必须 是[num_nodes, *]，因此在上方代码, 我们执行了deg.view(-1, 1)操作，使得数据形状为[num_nodes, 1]，然后才将数据传给propagate()方法。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### aggregate方法的覆写\n",
    "\n",
    "在前面的例子的基础上，我们增加如下的aggregate方法。通过观察运行结果我们 可 以 看 到 ， 我 们 覆 写 的 aggregate 方 法 被 调 用 ， 同 时 在 super(GCNConv, self).__init__(aggr='add')中传递给aggr参数的值被存储到了self.aggr属性中。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features : 1433, \n",
      "self.aggr: add\n",
      "`aggregate` is called\n",
      "torch.Size([2708, 64])\n"
     ]
    }
   ],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n",
    "        # aggr : 聚合方式 => add\n",
    "        # flow=\"source_to_target\" : 表示消息从源节点传播到目标节点\n",
    "        self.linear = torch.nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        :param x: [num_nodes, in_channels]\n",
    "        :param edge_index: [2, num_edges]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # step 1 : 向邻接矩阵添加自环边\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # step 2 : 对节点表征做线性变换\n",
    "        x = self.linear(x)\n",
    "        # step 3 : 计算归一化系数\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # step 4-5 : 开启消息传播\n",
    "        return self.propagate(edge_index=edge_index, x=x, norm=norm, deg=deg.view(-1, 1))\n",
    "\n",
    "    def message(self, x_j, norm, deg_i):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x_j: [num_edges, out_channels]\n",
    "        :param norm: 归一化系数\n",
    "        :param deg_i:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return norm.view(-1, 1) * x_j * deg_i\n",
    "    def aggregate(self, inputs, index, ptr, dim_size):\n",
    "        \"\"\"\n",
    "        :param inputs:\n",
    "        :param index:\n",
    "        :param ptr:\n",
    "        :param dim_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print('self.aggr:', self.aggr)\n",
    "        print(\"`aggregate` is called\")\n",
    "        return super().aggregate(inputs, index, ptr=ptr, dim_size=dim_size)\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "datasets = Planetoid(root='../../datasets/Cora', name=\"Cora\")\n",
    "# 获取第一张图\n",
    "data = datasets[0]\n",
    "print(\"num_features : {}, \".format(data.num_features))\n",
    "# 创建模型 : GCNConv(节点特征, out_channel)\n",
    "net = GCNConv(data.num_features, 64)\n",
    "# x : 节点属性矩阵，大小为 [num_nodes, num_node_features]\n",
    "# edge_index : 边索引矩阵，大小为[2, num_edges]\n",
    "# 第 0 行可称为头（head）节点、源（source）节点、邻接节点，第 1 行可称为尾（tail）节点、目标（target）节点、中心节点\n",
    "h_nodes = net(data.x, data.edge_index)\n",
    "print(h_nodes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### message_and_aggregate方法的覆写\n",
    "\n",
    "在一些案例中，“消息传递”与“消息聚合”可以融合在一起。对于这种情况，我们可以覆写message_and_aggregate方法，在message_and_aggregate方法中一块实现“消息传递”与“消息聚合”，这样能使程序的运行更加高效。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}