{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 数据完全存于内存的数据集类\n",
    "\n",
    "对于占用内存有限的数据集，我们可以将整个数据集的数据都存储到内存\n",
    "里。PyG为我们提供了方便的方式来构造数据完全存于内存的数据集类(简称为InMemory数据集类)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 使用数据集的一般过程\n",
    "\n",
    "PyG定义了使用数据的一般过程：\n",
    "1. 从网络上下载数据原始文件；\n",
    "2. 对数据原始文件做处理，为每一个图样本生成一个Data 对象；\n",
    "3. 对每一个Data对象执行数据处理，使其转换成新的Data对象；\n",
    "4. 过滤Data 对象；\n",
    "5. 保存Data 对象到文件；\n",
    "6. 获取Data对象，在每一次获取Data对象时，都先对Data对象做数据变换（于是获取到的是数据变换后的Data对象）。\n",
    "实际中并非需要严格执行每一个步骤"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### InMemoryDataset基类简介\n",
    "在PyG中，我们通过继承InMemoryDataset类来自定义一个数据可全部存储到内存的数据集类。\n",
    "\n",
    "InMemoryDataset类初始化方法参数说明 :\n",
    "\n",
    "- root: 字符串类型, 存储数据集的文件夹的路径。\n",
    "- 该文件夹下有两个文件夹:\n",
    "    - 一个文件夹为记录在raw_dir ，它用于存储未处理的文件，从网络上下载的数据集原始文件会被存放到这里；\n",
    "    - 另一个文件夹记录在processed_dir ，处理后的数据被保存到这里，以后从此文件夹下加载文件即可获得Data对象。\n",
    "\n",
    "- 注：raw_dir和processed_dir 是属性方法，我们可以自定义要使用的文件夹。\n",
    "\n",
    "----\n",
    "\n",
    "- transform :\n",
    "- 函数类型，一个数据转换函数，它接收一个Data对象并返回一个转换后的Data对象。此函数在每一次数据获取过程中都会被\n",
    "执行。获取数据的函数首先使用此函数对Data对象做转换，然后才返回数据。此函数应该用于数据增广(Data Augmentation)\n",
    "- 该参数默认值为None，表示不对数据做转换\n",
    "\n",
    "----\n",
    "\n",
    "- pre_transform : 函数类型，一个数据转换函数，它接收一个Data对象并返回一个转换后的Data对象。\n",
    "- 此函数在Data 对象被保存到文件前调用。\n",
    "- 因此它应该用于只执行一次的数据预处理。该参数默认值为 None, 表示不做数据预处理\n",
    "\n",
    "----\n",
    "\n",
    "- pre_filter : 函数类型，一个检查数据是否要保留的函数，它接收一个Data对象, 返回此 Data对象是否应该被包含在最终的数据集中。此函数也在Data对象被保存到文件前调用。该参数默认值为None，表示不做数据检查, 保留所有的数据。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 自定义数据集类\n",
    "\n",
    "通过继承InMemoryDataset类来构造一个我们自己的数据集类，我们需要实现四个基本方法 :\n",
    "\n",
    "- raw_file_names() : 这是一个属性方法，返回一个数据集原始文件的文件名列表, 数据集原始文件应该能在raw_dir文件夹中找到, 否则调用process() 函数下载文件到raw_dir文件夹\n",
    "- processed_file_names() 。这是一个属性方法，返回一个存储处理过的数据的文件的文件名列表, 存储处理过的数据的文件应该能在processed_dir 文件夹中找到，否则调用process() 函数对样本做处理, 然后保存处理过的数据到processed_dir 文件夹下的文件里\n",
    "\n",
    "- download() : 下载数据集原始文件到raw_dir文件夹。\n",
    "- process() : 处理数据，保存处理好的数据到processed_dir 文件夹下的文件。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (Temp/ipykernel_80636/3595442715.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\WANGTI~1\\AppData\\Local\\Temp/ipykernel_80636/3595442715.py\"\u001B[1;36m, line \u001B[1;32m3\u001B[0m\n\u001B[1;33m    通过继承InMemoryDataset类来构造一个我们自己的数据集类，我们需要实现四个基本方法 :\u001B[0m\n\u001B[1;37m                                                  ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid character in identifier\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 简化的InMemory数据集类示例"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform = None, pre_filter=None):\n",
    "        \"\"\"\n",
    "        构造函数\n",
    "        :param root: 存储数据集的文件路径\n",
    "        :param transform: 数据转换函数, 每次数据获取都会执行\n",
    "        :param pre_transform: 数据转换函数, 对象保存到文件前执行\n",
    "        :param pre_filter: 检查数据是否要保存的函数, 在Data对象保存的文件前调用\n",
    "        \"\"\"\n",
    "        super(MyOwnDataset, self).__init__(root=root, transform=transform, pre_transform=pre_transform, pre_filter=pre_filter)\n",
    "\n",
    "        # ================================================\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"\n",
    "        返回一个数据集原始文件的文件名列表\n",
    "        :return: ['some_file_1', 'some_file_2', ...]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"\n",
    "        返回一个存储处理过的数据的文件的文件名列表\n",
    "        :return:  ['data.pt']\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"\n",
    "        实现下载数据到self.raw_dir 文件夹的逻辑。\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        实现数据处理的逻辑:\n",
    "        1. 首先，我们从数据集原始文件中读取样本并生成Data对象, 所有样本的Data对象保存在列表 data_list 中。\n",
    "        2. 其次，如果要对数据做过滤的话，我们执行数据过滤的过程。\n",
    "        3. 接着，如果要对数据做处理的话，我们执行数据处理的过程\n",
    "        4. 最后，我们保存处理好的数据到文件\n",
    "        5. 但由于python保存一个巨大的列表是相当慢的，我们需要先将所有Data对象合并成一个巨大的Data对象再保存\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### InMemoryDataset数据集类实例\n",
    "\n",
    "我们以公开数据集PubMed 为例子，进行InMemoryDataset数据集实例分析。PubMed 数据集存储的是文章引用网络,文章对应图的结点,如果两篇\n",
    "文章存在引用关系（无论引用与被引用），则这两篇文章对应的结点之间存在边\n",
    "\n",
    "PyG中的Planetoid 数据集类包含了数据集PubMed的使用，因此我们直接基于Planetoid 类进行修改，得到PlanetoidPubMed数据集类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PlanetoidPubMed数据集类的构造"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.data import (InMemoryDataset, download_url)\n",
    "from torch_geometric.io import read_planetoid_data\n",
    "\n",
    "class PlanetoidPubMed(InMemoryDataset):\n",
    "\n",
    "    # url = 'https://gitee.com/rongqinchen/planetoid/raw/master/data'\n",
    "    url = 'https://github.com/kimiyoung/planetoid/raw/master/data'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform = None):\n",
    "        \"\"\"\n",
    "        节点代表文章，边代表引用关系。 训练、验证和测试的划分通过二进制掩码给出\n",
    "        :param root: 存储数据集的文件路径\n",
    "        :param transform: 数据转换函数, 每次数据获取都会执行\n",
    "        :param pre_transform: 数据转换函数, 对象保存到文件前执行\n",
    "        :param pre_filter: 检查数据是否要保存的函数, 在Data对象保存的文件前调用\n",
    "        \"\"\"\n",
    "        super(PlanetoidPubMed, self).__init__(root=root, transform=transform, pre_transform=pre_transform)\n",
    "\n",
    "        # ================================================\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        \"\"\"\n",
    "        数据集原始文件路径\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return osp.join(self.root, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        \"\"\"\n",
    "        已经处理过的数据集文件的路径\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return osp.join(self.root, 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\"\n",
    "        返回一个数据集原始文件的文件名列表\n",
    "        :return: ['some_file_1', 'some_file_2', ...]\n",
    "        \"\"\"\n",
    "        names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']\n",
    "        return ['ind.pubmed.{}'.format(name) for name in names]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"\n",
    "        返回一个存储处理过的数据的文件的文件名列表\n",
    "        :return:  'data.pt'\n",
    "        \"\"\"\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"\n",
    "        实现下载数据到self.raw_dir 文件夹的逻辑。\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for name in self.raw_file_names:\n",
    "            download_url(\"{}/{}\".format(self.url, name), self.raw_dir)\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        实现数据处理的逻辑:\n",
    "        1. 首先，我们从数据集原始文件中读取样本并生成Data对象, 所有样本的Data对象保存在列表 data_list 中。\n",
    "        2. 其次，如果要对数据做过滤的话，我们执行数据过滤的过程。\n",
    "        3. 接着，如果要对数据做处理的话，我们执行数据处理的过程\n",
    "        4. 最后，我们保存处理好的数据到文件\n",
    "        5. 但由于python保存一个巨大的列表是相当慢的，我们需要先将所有Data对象合并成一个巨大的Data对象再保存\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 读取原始数据\n",
    "        data = read_planetoid_data(self.raw_dir, 'pubmed')\n",
    "        # 数据预处理\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        # 保存数据集\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}()\".format(self.name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 该数据集类的使用\n",
    "\n",
    "该类初始化方法的参数说明见代码。代码中还实现了raw_dir() 和 processed_dir()两个属性方法，通过修改返回值，我们就可以修改要使\n",
    "用的文件夹\n",
    "\n",
    "----\n",
    "\n",
    "在我们生成一个PlanetoidPubMed类的对象时，程序运行流程如下:\n",
    "\n",
    "首先，检查数据原始文件是否已下载:\n",
    "- 检查self.raw_dir 目录下是否存在raw_file_names() 属性方法返回的每个文件\n",
    "- 如有文件不存在，则调用download() 方法执行原始文件下载。self.raw_dir 为 osp.join(self.root, 'raw')\n",
    "\n",
    "其次，检查数据是否经过处理:\n",
    "\n",
    "1. 首先 : 检查self.processed_dir 目录下是否存在 pre_transform.pt 文件\n",
    "- 如果存在，意味着之前进行过数据变换，接着需要加载该文件，以获取之前所用的数据变换的方法，并检查它与当前 pre_transform 参数指定的方法是否相同 如果不相同则会报出一个警告，\"The pre_transform argument differs from the one used in ……\"。\n",
    "- self.processed_dir为osp.join(self.root, 'processed')\n",
    "2. 其次 : 检查之前的样本过滤的方法：检查self.processed_dir目录下是否存在pre_filter.pt 文件\n",
    "- 如果存在, 则加载该文件并获取之前所用的样本过滤的方法, 并检查它与当前 pre_filter 参数指定的方法是否相同\n",
    "3. 接着 : 检查是否存在处理好的数据：检查self.processed_dir目录下是否存在self.processed_file_names属性方法返回的所有文件，如有文件不存在\n",
    "\n",
    "则需要执行以下的操作 :\n",
    "\n",
    "\n",
    "1. 调用process() 方法，进行数据处理。\n",
    "2. 如果pre_transform 参数不为 None，则调用 pre_transform() 函数进行数据处理。\n",
    "3. 如果pre_filter 参数不为None，则进行样本过滤(此例子中不需要进行样本过滤，pre_filter 参数为None)\n",
    "4. 保存处理好的数据到文件，文件存储在 processed_paths() 属性方法返回的文件路径。如果将数据保存到多个文件中，则返回的路径有多个\n",
    "5. processed_paths() 属性方法是在基类中定义的，它对self.processed_dir文件夹与processed_file_names()属性方法的返回每一个文件名做拼接，然后返回"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 查看数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "19717\n",
      "88648\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "dataset = PlanetoidPubMed('dataset/PlanetoidPubMed')\n",
    "print(dataset.num_classes)\n",
    "print(dataset[0].num_nodes)\n",
    "print(dataset[0].num_edges)\n",
    "print(dataset[0].num_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到这个数据集包含三个分类任务，共19,717个结点，88,648条边，节点特征维度为500。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}