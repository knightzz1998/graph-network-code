{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 基于图神经网络的节点表征学习\n",
    "\n",
    "本节中，我们将学习实现多层图神经网络的方法, 并以节点分类任务为例, 学习训练图神经网络的一般过程\n",
    "我们将以Cora数据集为例子进行说明, Cora是一个论文引用网络，节点代表论文, 如果两篇论文存在引用关系, 则对应的两个节点之间存在边, 各节点的属性都是一个1433维的词包特征向量。我们的任务是预测各篇论文的类别（共7类）\n",
    "\n",
    "我们还将对MLP和GCN, GAT（两个知名度很高的图神经网络） 三类神经网络在节点分类任务中的表现进行比较分析，以此来展现图神经网络的强\n",
    "大和论证图神经网络强于普通深度神经网络的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 准备工作\n",
    "\n",
    "1. 获取并分析数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# 设置数据集的正则化\n",
    "dataset = Planetoid(root='dataset', name='Cora', transform=NormalizeFeatures())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "数据集 : Cora()\n",
      "数据集中图的数量 : 1\n",
      "数据集的特征数量 : 1433\n",
      "数据集的类别数量 : 7\n",
      "=================================================\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "=================================================\n",
      "节点数 : 2708 \n",
      "边的数量 : 10556 \n",
      "平均节点的度 : 3.8980797636632203 \n",
      "可训练的节点数 : 75.4000015258789 \n",
      "包含的独立节点数 : False \n",
      "包含的环形节点数 : False \n",
      "是否是无向图 : True \n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DevApp\\anaconda3\\envs\\Graph_Network\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n",
      "D:\\DevApp\\anaconda3\\envs\\Graph_Network\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_code.utils.graph_info import getGraphInfo, getDatasetInfo\n",
    "\n",
    "# 打印数据集信息\n",
    "getDatasetInfo(dataset)\n",
    "\n",
    "# 获取第一张图\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "getGraphInfo(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以看到，Cora图拥有2,708个节点和10,556条边，平均节点度为3.9,\n",
    "训练集仅使用了140个节点，占整体的5%。我们还可以看到，这个图是无向图，不存在孤立的节点。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据转换（transform）在将数据输入到神经网络之前修改数据，这一功能可用于 实现数据规范化或数据增强\n",
    "\n",
    "我们使用NormalizeFeatures进行节点 特征归一化，使各节点特征总和为1。\n",
    "其他的数据转换方法请参阅[torch-geometric.transforms](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch-geometric-transforms)。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 可视化节点表征分布的方法\n",
    "\n",
    "我们先利用TSNE方法将高维的节点表征映射到二维平面空间，然后在二维平面画出节点，这样我们就实现了节点表征分布的可视化。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(out, color):\n",
    "    \"\"\"\n",
    "    :param out: out 是图神经网络模型的参数\n",
    "    :param color:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    z = TSNE(n_components=2)\n",
    "    z.fit_transform(out.detach().cpu().numpy())\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.scatter(z[:, 0], z[:, 1], s = 70, color=color, cmaps = \"Set2\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 使用MLP神经网络进行节点分类\n",
    "理论上，我们应该能够仅根据文章的内容，即它的词包特征表征（bag-of-words\n",
    "feature representation）来推断文章的类别，而无需考虑文章之间的任何关系信息。\n",
    "接下来, 让我们通过构建一个简单的MLP神经网络来验证这一点。此神经网络只对输入节点的表征做变换，它在所有节点之间共享权重。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们的MLP由两个线程层、一个ReLU非线性层和一个dropout操作组成。第一个线 程 层 将 1433 维 的 节 点 表 征 嵌 入 (embedding) 到 低 维 空 间 中 (hidden_channels=16), 第 二 个 线 性 层 将 节 点 表 征 嵌 入 到 类 别 空 间 中 (num_classes=7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (lin2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features: object, num_classes: object, hidden_channels: object) -> object:\n",
    "        super(MLP, self).__init__()\n",
    "        # 设置随机种子\n",
    "        torch.manual_seed(1234)\n",
    "        self.lin1 = nn.Linear(num_features, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: x [num_nodes, num_features]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = self.lin1(x) # [num_nodes, hidden_channels]\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x) # [num_nodes, num_classes]\n",
    "        return x\n",
    "\n",
    "model = MLP(dataset.num_features, dataset.num_classes, hidden_channels=16)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP神经网络的训练\n",
    "我们利用交叉熵损失和Adam优化器来训练这个简单的MLP神经网络。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义Adam优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义训练方法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    # 清除梯度\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x)\n",
    "    # 根据训练节点计算loss值\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新梯度\n",
    "    optimizer.step()\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:03<00:26,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 001, Loss : 0.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:06<00:23,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 002, Loss : 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:10<00:20,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 003, Loss : 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:13<00:16,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 004, Loss : 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:16<00:12,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 005, Loss : 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:19<00:09,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 006, Loss : 0.2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:22<00:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 007, Loss : 0.2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:25<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 008, Loss : 0.2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:28<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 009, Loss : 0.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(1, 10)):\n",
    "    loss = 0\n",
    "    for item in range(500):\n",
    "        loss = train()\n",
    "    print(f'Epoch : {epoch:03d}, Loss : {loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP神经网络的测试\n",
    "训练完模型后，我们可以通过测试来检验这个简单的MLP神经网络在测试集上的表现"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x) # [num_nodes. num_classes]\n",
    "    pred = out.argmax(dim=1)\n",
    "    # 测试集精确度\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "    # acc\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "    return test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.5350\n"
     ]
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'test accuracy : {test_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}